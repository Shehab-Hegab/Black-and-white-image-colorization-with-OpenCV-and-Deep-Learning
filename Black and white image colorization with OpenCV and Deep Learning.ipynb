{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "BGuy8kNUCB6h",
        "outputId": "ed8d261e-5aec-4444-bf3d-06bde1a099a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 3-4: truncated \\UXXXXXXXX escape (<ipython-input-7-822af86669d7>, line 9)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-822af86669d7>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    img_path = '\"C:\\Users\\admin\\OneDrive\\سطح المكتب\\OIP.jpeg\"'\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 3-4: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from cv2 import dnn\n",
        "\n",
        "#--------Model file paths--------#\n",
        "proto_file = 'Model\\colorization_deploy_v2.prototxt'\n",
        "model_file = 'Model\\colorization_release_v2.caffemodel'\n",
        "hull_pts = 'Model\\pts_in_hull.npy'\n",
        "img_path = 'OIP.jpeg'\n",
        "#--------------#--------------#\n",
        "\n",
        "#--------Reading the model params--------#\n",
        "net = dnn.readNetFromCaffe(proto_file,model_file)\n",
        "kernel = np.load(hull_pts)\n",
        "#-----------------------------------#---------------------#\n",
        "\n",
        "#-----Reading and preprocessing image--------#\n",
        "img = cv2.imread(img_path)\n",
        "scaled = img.astype(\"float32\") / 255.0\n",
        "lab_img = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)\n",
        "#-----------------------------------#---------------------#\n",
        "\n",
        "# add the cluster centers as 1x1 convolutions to the model\n",
        "class8 = net.getLayerId(\"class8_ab\")\n",
        "conv8 = net.getLayerId(\"conv8_313_rh\")\n",
        "pts = kernel.transpose().reshape(2, 313, 1, 1)\n",
        "net.getLayer(class8).blobs = [pts.astype(\"float32\")]\n",
        "net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]\n",
        "#-----------------------------------#---------------------#\n",
        "\n",
        "# we'll resize the image for the network\n",
        "resized = cv2.resize(lab_img, (224, 224))\n",
        "# split the L channel\n",
        "L = cv2.split(resized)[0]\n",
        "# mean subtraction\n",
        "L -= 50\n",
        "#-----------------------------------#---------------------#\n",
        "\n",
        "# predicting the ab channels from the input L channel\n",
        "\n",
        "net.setInput(cv2.dnn.blobFromImage(L))\n",
        "ab_channel = net.forward()[0, :, :, :].transpose((1, 2, 0))\n",
        "# resize the predicted 'ab' volume to the same dimensions as our\n",
        "# input image\n",
        "ab_channel = cv2.resize(ab_channel, (img.shape[1], img.shape[0]))\n",
        "\n",
        "\n",
        "# Take the L channel from the image\n",
        "L = cv2.split(lab_img)[0]\n",
        "# Join the L channel with predicted ab channel\n",
        "colorized = np.concatenate((L[:, :, np.newaxis], ab_channel), axis=2)\n",
        "\n",
        "# Then convert the image from Lab to BGR\n",
        "colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n",
        "colorized = np.clip(colorized, 0, 1)\n",
        "\n",
        "# change the image to 0-255 range and convert it from float32 to int\n",
        "colorized = (255 * colorized).astype(\"uint8\")\n",
        "\n",
        "# Let's resize the images and show them together\n",
        "img = cv2.resize(img,(640,640))\n",
        "colorized = cv2.resize(colorized,(640,640))\n",
        "\n",
        "result = cv2.hconcat([img,colorized])\n",
        "\n",
        "cv2.imshow(\"Grayscale -> Colour\", result)\n",
        "\n",
        "cv2.waitKey(0)"
      ]
    }
  ]
}